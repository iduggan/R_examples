---
title: "code_challlenge_bella"
format: html
editor: source
---

# Code Challenge:

##1. Load Data Into Environment

```{r}
bps_model_number_names <- read.csv("input_data/bps_model_number_name.csv")

combine_raw <- read.csv("input_data/combine_raw.csv")

LF16_BPS_200 <- read.csv("input_data/LF16_BPS_200.csv")

ref_con_modified <- read.csv("input_data/ref_con_modified.csv")

scls_aoi_attributes <- read.csv("input_data/scls_aoi_attributes.csv")

```

##2. Merge & Filter for past data
```{r}
library(ggplot2)
library(dplyr)
library(tidyverse)

filtered_pivot <- merge(bps_model_number_names, ref_con_modified, by = "Model_Code") %>%
 pivot_longer(cols = c(A:E, Agriculture:UE)) %>% 
  filter(Model_Code == "13040_32_43_44_49" |  Model_Code == "15070_44" | Model_Code == "13670_32_44") %>%
  unite(model_label, "Model_Code", "name", sep = "", remove = FALSE) 

colnames(filtered_pivot)[colnames(filtered_pivot) == "name"] <- "refLabel"

colnames(filtered_pivot)[colnames(filtered_pivot) == "value"] <- "RefPercent"

```

#Merging for Present Data
```{r}
colnames(scls_aoi_attributes)[colnames(scls_aoi_attributes) == "VALUE"] <- "Var2" #changing to Var2, same values as Var2 in combine_raw

combine <- left_join(combine_raw, scls_aoi_attributes %>% dplyr::select(2, 4), by = "Var2") #Combining same values

colnames(LF16_BPS_200)[colnames(LF16_BPS_200) == "VALUE"] <- "Var1" #Var1 in combine = VALUE in LF16_BPS_200; changing to match and combine

combine <- left_join(combine, LF16_BPS_200 %>% dplyr::select(1:5), by = "Var1") #Combining both by Var1 to add model_label, BPS_names, and total count for each freq and Var

# calculate current sclass percents
combine <- combine %>%
  group_by(Var1, BPS_MODEL) %>%
  mutate(total_count = sum(Freq)) %>%
  mutate(currentPercent = as.integer((Freq/total_count)*100)) %>%
  unite(model_label, c("BPS_MODEL", "LABEL"))

```

##Filter and Reordering Present
```{r}

filtered_combine <- filter(combine, BPS_CODE == "13040" | BPS_CODE == "13670" | BPS_CODE == "15070")

filtered_combine$BPS_NAME <- factor(filtered_combine$BPS_NAME, levels = unique(filtered_combine$BPS_NAME))

# Reorder the dataset by the BPS_NAME column
filtered_combine <- arrange(filtered_combine, BPS_NAME)

```


#Put it together
```{r}
library(janitor)

past_and_present <- left_join(filtered_pivot, filtered_combine, by = "model_label") %>% 
  drop_na("RefPercent") %>% 
  mutate(currentPercent = as.numeric(currentPercent), currentPercent = ifelse(is.na(currentPercent), 0, currentPercent)) %>%
          mutate(total_count = as.numeric(total_count),  total_count = ifelse(is.na(total_count), 0, total_count)) %>%
          select(-c(BPS_CODE, ZONE, Model_Code)) %>%
                         select(c(Freq, 
                                  Var1, 
                                  Var2,
                                  BpS_Name,
                                  refLabel,
                                  model_label,
                                  RefPercent,
                                  currentPercent,
                                  total_count)) %>%
                          rename(count = Freq,
                                 bps_value = Var1,
                                 scl_value = Var2,
                                 bps_name = BpS_Name) %>%
                          clean_names() 

```

> Okay, when we met you saw my chart was correct right? I don't know WHAT happened, but when I loaded it the next day I was no longer seeing values for bps, scl, current_percent, or total_count- which is screwing up my final graph... I did edit filtered_pivot to include refLabel because I didn't have that before and needed it; but that shouldn't mess up my Var1, Var2, etc. you wouldn't think, right? 

## Make Chart
```{r}
# Load the tidyr library
library(tidyr)

re_past_present <- past_and_present %>%
  mutate(total_count = ifelse(total_count == 0, max(total_count), total_count)) %>%
  arrange(desc(total_count))  %>%
  ungroup() %>%
  dplyr::filter(dense_rank(desc(total_count)) < 4) %>%
  dplyr::select(c("bps_name", "ref_label",  "current_percent", "ref_percent")) %>%
  pivot_longer(
    cols = c(`ref_percent`, `current_percent`), 
    names_to = "ref_cur", 
    values_to = "percent"
  )

re_past_present$ref_label <- factor(re_past_present$ref_label, 
                                 levels = c(
                                   "Developed",
                                   "Agriculture",
                                   "UE",
                                   "UN",
                                   "E",
                                   "D",
                                   "C",
                                   "B",
                                   "A"))

plot_past_present <-
  ggplot(re_past_present, aes(fill = factor(ref_cur), y = percent, x = ref_label)) + 
  geom_col(width = 0.8, position = position_dodge()) +
  coord_flip() +
  facet_grid(. ~BpS) +
  scale_x_discrete(limits = (levels(re_past_present$ref_label))) +
  labs(
    title = "Succession Classes past and present",
    subtitle = "Top BpSs selected for illustration. Not all succession classes present in all BpSs",
    caption = "Data from landfire.gov.",
    x = "",
    y = "Percent") +
  theme_minimal(base_size = 12) +
  theme(plot.caption = element_text(hjust = 0, face = "italic"), 
        plot.caption.position =  "plot") +
  scale_fill_manual(values = c("#3d4740", "#32a852" ), 
                    name = " ", 
                    labels = c("Present",
                               "Past")) +
  facet_wrap(~bps_name, nrow(3),labeller = labeller(bps_name = label_wrap_gen())) +
  theme(panel.spacing = unit(.05, "lines"),
        panel.border = element_rect(color = "black", fill = NA, size = 1), 
        strip.background = element_rect(color = "black", size = 1))

plot_past_present

```


#Reflection:

ii. From this challenge my comfortability with data wrangling has improved tremendously. At the start of this challenge I was still rusty/ not completely comfortable and having to ask chatgpt questions about inputting data and merging datasets. Now I feel that if we were given a second code challenge, with the information I've learned from this first, I might be able to work through things more efficiently.

iii. I think I did a good job at reflecting/ note taking as I went along and struggled. I made notes for myself so if I took a break and came back another day, or a few days later, I still knew what I had going on and needed to work with. I think if I were working with a partner on something like this that form of note taking would be helpful and make things easier for two people. Similarly, I could definitely improve on making comments within code, that's something I need to get in the habit of doing.

##Annotations:

> merge: merge is used to merge 2 datasets together by a specified column.

>pivot_longer: apart of "tidyr," used to shift datasets from a wide to long format.

>filter: used to filtered datasets by a specific attribute within a column.

>colnames: used to rename columns.

>left_join: used to join the left side of one dataset to all the matching attributes on the right of another dataset.

>group_by: used in conjunction with "mutate()" or other functions of the "dplyr" package,enabling you to group one or more variables in a dataset and manipulate them by their group.

>unite: concentrates values in R by tidying and uniting messy columns, used to unite Model_Code and name to create model label.
